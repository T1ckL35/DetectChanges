name: matrix tests
on:
  push:
  workflow_dispatch:
    inputs:
      logLevel:
        description: 'Log level'
        required: true
        default: 'warning'
        type: choice
        options:
        - info
        - warning
        - debug
      # tags:
      #   description: 'Test scenario tags'
      #   required: false
      #   type: boolean
      # environment:
      #   description: 'Environment to run tests against'
      #   type: environment
      #   required: true

jobs:

  build_configuration:
    name: Build Configuration
    runs-on: ubuntu-latest
    # To add in at some point
    # if: github.event.pull_request.merged == true
    # Map a step output to a job output. A shortcut way to defining a variable instead of the full path
    #     e.g, 
    #outputs:
    #  matrix: ${{ steps.run_script.outputs.MODULES_MATRIX }}    # Will be used in another job to run module tests with
    outputs:
      modules_json_list: ${{ steps.build_changed_files.outputs.modules_list_output }}    # json list of modules to use as a matrix input to determine the next available release/tag version
      all_changed_files: ${{ steps.build_changed_files.outputs.changed_files }}          # diff of all current files that have changed. ALso used to build a configuration on if a module has tests to run
      #env:
    #  NBS_MODULE_MATRIX_NAME: "MODULES_MATRIX"                # Defines the variable name in GITHUB_OUTPUT that the python modules script outputs the data to
    steps:
      - id: checkout-codebase
        name: Checks out the codebase as needed. If this is a PR then it uses a fetch-depth of 2 to determine the changes. Otherwise the fetch-depth is 0 to get the full git history
        uses: actions/checkout@v4
        with:
            # Note, if a depth of 2 is used then we will need to checkout again with a depth of zero in a later step so that GitVersion has the full repo history to be able to create a semver version with..
            fetch-depth: ${{ github.event_name == 'pull_request' && 2 || 0 }}

      - id: build_changed_files
        name: Builds a list of changed modules and their files. Output to 'changed_files' variable
        run: |
            # Pushes output to $GITHUB_OUTPUT so it can be used in other jobs/steps
            if ${{ github.event_name == 'pull_request' }}; then
                echo "changed_files=$(git diff --name-only -r HEAD^1 HEAD | xargs)" >> $GITHUB_OUTPUT
                export changed_modules=$( git diff --name-only origin/$GITHUB_BASE_REF ${{ github.event.after }} -- modules | grep -E 'modules/.*/' | cut -d/ -f2 | uniq)
            else
                echo "changed_files=$(git diff --name-only ${{ github.event.before }} ${{ github.event.after }} | xargs)" >> $GITHUB_OUTPUT
                export changed_modules=$( git diff --name-only ${{ github.event.before }} ${{ github.event.after }} -- modules | grep -E 'modules/.*/'  | cut -d/ -f2 | uniq)
            fi
            echo "$changed_modules"
            echo "modules_list_output=$(echo "$changed_modules" | jq  --raw-input .  | jq --slurp . | jq -c .)"  >> $GITHUB_OUTPUT

            # extra work. Here we create a json list of objects for each module
            # then we pull out the module names as a list to run the matrix to determine the next module versions
            #cat json/combined.json | jq -r -c '[.[].module] | unique'

            # New code - create a json object of each module and their current tag version. Also include any types of tests that need running
            # Should give something like:
            # [
            #   {
            #     "name": "module1",
            #     "tests": ["unit", "integration"],
            #     "tags": {
            #       "current": "0.0.2",
            #       "next": ""
            #     },
            #   },
            #   {
            #     "name": "module2",
            #     "tests": ["unit"],
            #     "tags": {
            #       "current": "0.0.1",    # todo: handle no current tags as 0.0.1
            #       "next": ""
            #     },
            #   },
      # - id: setup_python
      #   name: Set up Python to use
      #   uses: actions/setup-python@v5
      #   with:
      #       python-version: 3.12
    
      # - id: run_script
      #   name: Run script
      #   run: |
      #       # causes failure if python script fails
      #       set -e 
      #       python3 modules/${{ matrix.module }}/test.py -f "${{ steps.build_changed_files.outputs.changed_files }}" -o "${{ env.NBS_MODULE_MATRIX_NAME }}"
  
    




  # run_tests:
  #   strategy:
  #     matrix:
  #       #module: [module1, module2]
  #       include:
  #         - module: module1
  #           unit: true
  #         - module: module1
  #           bdd: true
  #         #- module: module2
  #         #  unit: true
  #         #  npm: 8
  #   runs-on: ${{ matrix.os }}  modules_json_list
  #   steps:
  #     - uses: actions/setup-node@v4
  #       with:
  #         node-version: ${{ matrix.node }}
  #     - if: ${{ matrix.npm }}
  #       run: npm install -g npm@${{ matrix.npm }}
  #     - run: npm --version

  build_tests_config:
    name: Build Tests Configuration
    runs-on: ubuntu-latest
    needs: [build_configuration]
    steps:
      - id: run_test
        name: Run the specified test
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: setup_python
        name: Set up Python to use
        uses: actions/setup-python@v5
        with:
          python-version: 3.12
      - id: sort_pythonpath
        name: Sorts the PYTHONPATH so we can import custom python modules
        run: |
          echo "PYTHONPATH=$PYTHONPATH:${{ github.workspace }}" >> $GITHUB_ENV
      - name: show python path
        run: |
            python -c "import sys; import os; print('\n'.join(sys.path)); print(os.getcwd())"
      - name: Run a python script inline to convert a bash space deparated string into a json list
        shell: python
        run: |
          # codepath isn't in PYTHONPATH
          # ${{ github.workspace }} # e.g, /home/runner/work/my-repo-name/my-repo-name
          from scripts import matrix_helper

          # Create an instance of the MatrixHelper class
          app = matrix_helper.MatrixHelper()
          
          # Configure logging to output to both file and console
          app.output_logging()
          
          # Generate a list of includes for module1
          item = "module1"
          list = ["unit", "bdd"]
          # Generate includes using the helper method. Note, using the extra parameter defaults of "module" and "test"
          includes = app.generate_includes_from_list(item, list)
          #print(includes)

          # Generate a list of includes for module2
          item = "module2"
          list = ["unit"]
          # Merge all the includes into a single list
          includes.extend(
            app.generate_includes_from_list(item, list)
          )
          final_includes = app.wrap_includes(includes, "TESTS_MATRIX_OUTPUT")
          app.output_json(final_includes)


  run_module_tests:
    needs: [get-changed-next-module-versions]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - module: "module1"
            test: "unit"
          - module: "module1"
            test: "bdd"
    steps:
      - id: run_test
        name: Run the specified test
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - run: |
          echo "For Module: ${{matrix.module}} Running Test: ${{matrix.test}}"    
      # - run: echo ${{matrix}}
      # - run: echo ${{matrix.test}}
      # - name: Run tests
      #   run: |
      #     echo "Running tests for ${{ matrix.site }} in ${{ matrix.test }}"
      #     # Add your test command here


  get-changed-next-module-versions:
    runs-on: ubuntu-latest
    needs:
      - build_configuration
    #env:
    #  OUTPUT1: ${{needs.get_files.outputs.output1}}
    strategy:
      fail-fast: false
      matrix:
        module_name: ${{ fromJSON(needs.build_configuration.outputs.modules_json_list) }}    # ["module1", "module2"]
    steps:
      - id: checkout-codebase
        name: Checks out the codebase as needed
        uses: actions/checkout@v4
        with:
            fetch-depth: 0
      - id: install_gitversion
        name: Install GitVersion
        uses: gittools/actions/gitversion/setup@v3.2.1
        with:
            versionSpec: '6.2.x'
      - id: version_step_module # step id used as reference for output values
        name: Determine Module Version. Todo is make this dynamic
        uses: gittools/actions/gitversion/execute@v3.2.1
        with:
            # NOTE: Tried specifying a configfile in the module's folder but it does NOT work.
            #   This is the only way it seems to honor using a tag-prefix config value
            overrideConfig: |
                tag-prefix=${{ matrix.module_name }}-
      - id: check_module_version
        name: Debug check of module1's next version to use
        run: |
          echo "Module 1 Next version is ${{ steps.version_step_module.outputs.MajorMinorPatch }}"
      - run: mkdir -p module_versions
      - name: Create a File
        # works but testing outputting a json object to the file to then later be merged together again
        # run: echo "${{ matrix.module_name }}-${{ steps.version_step_module.outputs.MajorMinorPatch }}" > module_versions/${{ matrix.module_name }}.txt
        run: echo "${{ matrix.module_name }}-${{ steps.version_step_module.outputs.MajorMinorPatch }}" > module_versions/${{ matrix.module_name }}.txt
      - name: Upload blob report to GitHub Actions Artifacts
        #if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.module_name }}                # artifact reference name - not the filename!
          path: module_versions/${{ matrix.module_name }}.txt    # actual filename and path
          retention-days: 1    # minimum retention
          overwrite: true      # deletes and creates new same named file if found

  # # https://github.com/actions/runner/pull/2477
  # # parallel matrix doesn't yet support dynamic outputs
  # # hence storing individual output in text files and re-joining them later
  merge_module_versions:
    #if: always()
    needs: [get-changed-next-module-versions]
    runs-on: ubuntu-latest
    #outputs:
    #  modules_json_list: ${{ steps.build_changed_files.outputs.modules_list_output }}
    steps:
      - id: retrieve_changed_module_versions
        name: Download blob module_versions from GitHub Actions Artifacts which stored the next changed module versions to use
        uses: actions/download-artifact@v4
        with:
          path: module_versions/
          pattern: module*
          merge-multiple: true

      - id: combine_module_versions
        run: |
          # echo "modules_list_output=$(echo "$changed_modules" | jq  --raw-input .  | jq --slurp . | jq -c .)"  >> $GITHUB_OUTPUT

          # # works to create a single space separated string
          # module_versions_string="$(cat module_versions/module* | tr '\n' ' ' | xargs)"
          # echo "Module Versions String: $module_versions_string"
          # echo "module_versions_string=$module_versions_string" >> "$GITHUB_OUTPUT"

          # better way to create json list
          module_versions_string="$(cat module_versions/* | jq  --raw-input .  | jq --slurp . | jq -c .)"
          echo "Module Versions String: $module_versions_string"
          echo "module_versions_string=$module_versions_string" >> "$GITHUB_OUTPUT"


          # JSON tests:
          # Build a json object frmo data
          # echo "{\"module_name\": \"$myname1\", \"version\": \"$myval1\"}" | jq

          # Merge two json objects into a json list containing them
          #     jq -s '.' file1.json file2.json > file_combined.json


          # # BASH SCRIPT VARIABLES to JSON
          MODULE_NAME=module1
          MODULE_NEXT_VERSION=0.0.3
          # -c = --compact-output to a single line. Easier to handle in bash
          JSON_STRING=$( jq -n -c \
                            --arg bn "$MODULE_NAME" \
                            --arg on "$MODULE_NEXT_VERSION" \
                            '{module_name: $bn, module_next_version: $on}' )
          echo "JSON_STRING=$JSON_STRING"
          #
          ## GIVES: { "module_name": "module1", "module_next_version": "0.0.3" }

      #- run: echo "module_next_versions=$(cat module_versions/module*)" >> $GITHUB_OUTPUT

      - id: check_module_versions_output
        run: echo ${{ steps.combine_module_versions.outputs.module_versions_string }}
      
      # - id: setup_python
      #   name: Set up Python to use
      #   uses: actions/setup-python@v5
      #   with:
      #     python-version: 3.12

      # - id: run_script
      #   name: Run script
      #   env:
      #       SEMVER: ${{ steps.version_step_module1.outputs.MajorMinorPatch }}    # example of pulling in a previous step's variable as an environment variable in this step. Not currently used.
      #   run: |
      #       # causes failure if python script fails
      #       set -e

      #       # Note, -o defines the name of a variable that is added to GITHUB_OUTPUT with the python script output
      #       python3 scripts/test.py -f "${{ steps.build_changed_files.outputs.changed_files }}" -o "${{ env.NBS_MODULE_MATRIX_NAME }}"

      #       # check the python script exited ok (a python exception caught will trigger a sys.exit(1) and fail the step/workflow)
      #       if [[ $? = 0 ]]; then
      #           echo "success"
      #       else
      #           echo "failure: $?"
      #       fi

